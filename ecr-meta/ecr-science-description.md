An audio-based bird detection and identification system hasbecome more popular in recent years. In particular, this audio-based system is useful for ecosystem diversity monitoring andeducation  purpose  [1].  Researchers  working  on  bioacousticsounds  can  also  use  this  system  to  process  large  amount  ofaudio  data  more  efficiently.  On  the  other  hand,  bird  loverscan use the audio-based bird indentification system to identifybirds from the recordings they recorded themselves. BirdCLEFbird identification challenge is part of the LifeClef workshops.It  provides  a  large  collection  of  bird  song  recordings,  whichare originally submitted by bird lovers from all over the worldfrom Xeno-Canto. Xeno-Canto is dedicated to share bird songsfrom all over the word. The purpose and the goal of this projectis  to  “popularise  bird  sound  recording  worldwide,  improveaccessibility  of  bird  sounds,  and  increase  knowledge  of  birdsounds” [2].
Identifying  species  from  so  many  different  birds  is  chal-lenging  classification  task.  As  for  the  larger  scope  of  audioclassification,  CNN  has  been  the  most  popular  model  withthe best performance [3] [4]. CNN is also proven to performthe best for the bird classification research in recent years [5][6]  [7].  However,  all  the  research  mentioned  above  focusedon the machine learning models. Feature engineering is usedmostly in speech processing [8]. Fayek explored how MFCCand  filter  banks  are  different,  and  why  later  one  has  becomemore popular.
In processing the audio files, feature extraction is a criticalprocess  before  feeding  the  features  into  the  models.  Thisproject investigate and compare all possible features extractionmethods under the Librosa library. Features from these differ-ent methods are used on three different, yet standard machinelearning models: neural network, SVM and CNN. We exploredall the possible feature extraction methods in Librosa library. Based  on  the  shape  of  the  features,  7  individual  featuresextraction methods are selected, which are mfcc, chroma, mel,contrast, tonnetz, tempogram, and fourier tempogram. We alsocombine  the  features  based  on  their  individual  performanceand the result shows the combination method works far betterthan  individual  ones.The  results  shows  that  the  combinationof features has the best performance in all three models.

[1]  M. Lasseck, “Audio-based bird species identification with deep convo-lutional neural networks.”CLEF (Working Notes), vol. 2125, 2018.
[2]  X.  canto  Foundation.  About.  [Online].  Available:  https://www.xeno-canto.org/about/xeno-canto
[3]  S.  Hershey,  S.  Chaudhuri,  D.  P.  Ellis,  J.  F.  Gemmeke,  A.  Jansen,R.  C.  Moore,  M.  Plakal,  D.  Platt,  R.  A.  Saurous,  B.  Seyboldet  al.,“Cnn  architectures  for  large-scale  audio  classification,”  in2017  ieeeinternational  conference  on  acoustics,  speech  and  signal  processing(icassp).    IEEE, 2017, pp. 131–135.
[4]  S.  Abdoli,  P.  Cardinal,  and  A.  L.  Koerich,  “End-to-end  environmentalsound  classification  using  a  1d  convolutional  neural  network,”ExpertSystems with Applications, vol. 136, pp. 252–263, 2019.
[5]  S.   Kahl,   T.   Wilhelm-Stein,   H.   Hussein,   H.   Klinck,   D.   Kowerko,M.  Ritter,  and  M.  Eibl,  “Large-scale  bird  sound  classification  usingconvolutional  neural  networks.”  inCLEF  (working  notes),  2017,  vol.1866.
[6]  S.  Kahl,  T.  Wilhelm-Stein,  H.  Klinck,  D.  Kowerko,  and  M.  Eibl,“Recognizing  birds  from  sound-the  2018  birdclef  baseline  system,”arXiv preprint arXiv:1804.07177, 2018.
[7]  J.  Xie,  K.  Hu,  M.  Zhu,  J.  Yu,  and  Q.  Zhu,  “Investigation  of  differentcnn-based models for improved bird sound classification,”IEEE Access,vol. 7, pp. 175 353–175 361, 2019.
[8]  H.M.Fayek,“Speechprocessingformachinelearning:Filterbanks,mel-frequencycepstralcoeffi-cients(mfccs)andwhat’sin-between,”2016.[Online].Available:  https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html
